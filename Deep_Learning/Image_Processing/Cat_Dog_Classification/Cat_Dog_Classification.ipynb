{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab1a56fe",
   "metadata": {},
   "source": [
    "#### 목표 \n",
    "> * 사전학습 모델인 Backbone 모델의 종류와 개념을 알고, Transfer Learning의 개념을 설명할 수 있다.\n",
    "> * VGG, ResNet과 같은 기본적인 Backbone 모델을 불러와서 사용할 수 있다.\n",
    "> * Backbone 모델을 원하는 레이어(layer)만큼 새로 학습시켜서 사용할 수 있다.\n",
    "> * Backbone 모델을 Transfer Learning 시킴으로써 원하는 이미지를 분류시킬 수 있다.\n",
    "> * 이미 잘 학습되어 있는 모델을 가지고 이미지를 분류할 수 있다.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eda8e0",
   "metadata": {},
   "source": [
    "## 1. 강아지 고양이 분류기 : 모델 직접 설계\n",
    "#### tensorflow_datasets 데이터를 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665f89c6",
   "metadata": {},
   "source": [
    "```Python\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# 오류 무시\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "# 텐서플로우 데이터셋 로드(cats_vs_dog 활용, 786.68 MiB, 23262장)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# 시각화를 위한 matplotlib. 선명하게 하기 위해 retina 문장 추가\n",
    "\n",
    "\n",
    "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
    "    name='cats_vs_dogs',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    data_dir='~/Dataset/cats_vs_dogs/',\n",
    "    download=False,\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")\n",
    "# 데이터 스플릿\n",
    "\n",
    "\n",
    "print(raw_train)\n",
    "print(raw_validation)\n",
    "print(raw_test)\n",
    "# 데이터 확인\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "get_label_name = metadata.features['label'].int2str\n",
    "\n",
    "for idx, (image, label) in enumerate(raw_train.take(10)):  # 10개의 데이터를 가져 옵니다.\n",
    "    plt.subplot(2, 5, idx+1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'label {label}: {get_label_name(label)}')\n",
    "    plt.axis('off')\n",
    "# 10장의 데이터 이미지 확인\n",
    "# 강아지는 label 1로, 고양이는 label 0으로 설정되어 있음.\n",
    "\n",
    "\n",
    "IMG_SIZE = 160 # 리사이징할 이미지의 크기\n",
    "\n",
    "def format_example(image, label):\n",
    "    image = tf.cast(image, tf.float32)  # image=float(image)같은 타입캐스팅의  텐서플로우 버전입니다.\n",
    "    image = (image/127.5) - 1 # 픽셀값의 scale 수정\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    return image, label\n",
    "# 이미지 포맷 일치를 위한 함수.(타입캐스팅)\n",
    "\n",
    "\n",
    "IMG_SIZE = 160 # 리사이징할 이미지의 크기\n",
    "\n",
    "def format_example(image, label):\n",
    "    image = tf.cast(image, tf.float32)  # image=float(image)같은 타입캐스팅의 텐서플로우 버전.\n",
    "    image = (image/127.5) - 1 # 픽셀값의 scale 수정(-1~1 사이의 실수값으로)\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    return image, label\n",
    "# (160,160) 픽셀로 통일 및 각 픽셀 데이터값을 scaling\n",
    "\n",
    "\n",
    "train = raw_train.map(format_example)\n",
    "validation = raw_validation.map(format_example)\n",
    "test = raw_test.map(format_example)\n",
    "# train, validataion, test 데이터셋에 map함수를 이용해 적용\n",
    "\n",
    "\n",
    "print(train)\n",
    "print(validation)\n",
    "print(test)\n",
    "# 적용이 잘 됐는지 확인(160, 160, 3)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "\n",
    "get_label_name = metadata.features['label'].int2str\n",
    "\n",
    "for idx, (image, label) in enumerate(train.take(10)):\n",
    "    plt.subplot(2, 5, idx+1)\n",
    "    image = (image + 1) / 2\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'label {label}: {get_label_name(label)}')\n",
    "    plt.axis('off')\n",
    "# 이미지를 불러와 확인\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(filters=16, kernel_size=3, padding='same', activation='relu', input_shape=(160, 160, 3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(units=512, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])\n",
    "# 본격적인 모델 설계\n",
    "\n",
    "\n",
    "model.summary()\n",
    "# 모델 구조 확인\n",
    "\n",
    "\n",
    "learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "# 모델 compile 설정(optimizer, loss, metrics)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "# batch size와 shuffle buffer size 설정\n",
    "\n",
    "\n",
    "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "validation_batches = validation.batch(BATCH_SIZE)\n",
    "test_batches = test.batch(BATCH_SIZE)\n",
    "# BATCH_SIZE에 따라 32개의 데이터를 랜덤으로 뿌려줄 train_batches, validation_batches, test_batches를 생성\n",
    "\n",
    "\n",
    "validation_steps = 20\n",
    "loss0, accuracy0 = model.evaluate(validation_batches, steps=validation_steps)\n",
    "\n",
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))\n",
    "# 학습 전 초기 모델을 만들어서 평가\n",
    "# validation(검증)을 하기 위한 데이터셋인 validation_batches를 이용해 20번의 예측을 해 보고, 평균 loss와 평균 accuracy를 확인할 것.\n",
    "# => loss는 0.7, accuracy는 약 50%.\n",
    "\n",
    "\n",
    "EPOCHS = 10\n",
    "history = model.fit(train_batches,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=validation_batches)\n",
    "# 학습 시작\n",
    "# => 훈련 데이터셋에 대한 정확도(accuracy)는 약 90% 남짓, 검증 데이터셋에 대한 accuracy(val_accuracy)는 약 80% 조금 못 미치게 나옴\n",
    "\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "# 결과 시각화\n",
    "# validation accuracy를 보면 overfitting이 일어남을 알 수 있음\n",
    "\n",
    "\n",
    "for image_batch, label_batch in test_batches.take(1):\n",
    "    images = image_batch\n",
    "    labels = label_batch\n",
    "    predictions = model.predict(image_batch)\n",
    "    break\n",
    "\n",
    "predictions\n",
    "# 모델의 예측 결과를 확인\n",
    "# [고양이일 확률, 강아지의 확률] // [1.0, 0.0]에 가까울수록 label이 0인 고양이로, [0.0, 1.0]에 가까울수록 label이 1인 강아지로 예측\n",
    "\n",
    "\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "predictions\n",
    "# prediction 값들을 실제 추론한 라벨(0:고양이, 1:강아지)로 변환.\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "for idx, (image, label, prediction) in enumerate(zip(images, labels, predictions)):\n",
    "    plt.subplot(4, 8, idx+1)\n",
    "    image = (image + 1) / 2\n",
    "    plt.imshow(image)\n",
    "    correct = label == prediction\n",
    "    title = f'real: {label} / pred :{prediction}\\n {correct}!'\n",
    "    if not correct:\n",
    "        plt.title(title, fontdict={'color': 'red'})\n",
    "    else:\n",
    "        plt.title(title, fontdict={'color': 'blue'})\n",
    "    plt.axis('off')\n",
    "# 예측 결과를 시각화\n",
    "\n",
    "\n",
    "count = 0   # 정답을 맞춘 개수\n",
    "for image, label, prediction in zip(images, labels, predictions):\n",
    "    # [[YOUR CODE]]\n",
    "    if label.numpy() == prediction:\n",
    "        #맞았다\n",
    "        count += 1\n",
    "        \n",
    "\n",
    "print(count / 32 * 100)\n",
    "# 예측 결과가 얼마나 맞았는지 확인\u001f\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cafdc7",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#### model compile에서 정해야 할 3가지 요소\n",
    " * **optimizer**는 학습을 어떤 방식으로 시킬 것인지 결정. 어떻게 최적화시킬 것인지를 결정하기 때문에 최적화 함수라고 부르기도 함.\n",
    " * **loss**는 모델이 학습해나가야 하는 방향을 결정. 이 문제에서는 모델의 출력은 입력받은 이미지가 고양이인지 강아지인지에 대한 확률분포로 두었으므로, 입력 이미지가 고양이(label=0)일 경우 모델의 출력이 [1.0, 0.0]에 가깝도록, 강아지(label=1)일 경우 [0.0, 1.0]에 가까워지도록 하는 방향을 제시할 것.(sparce categorical crossentropy 사용)\n",
    " * **metrics**는 모델의 성능을 평가하는 척도. 분류 문제를 풀 때, 성능을 평가할 수 있는 지표인 정확도(accuracy), 정밀도(precision), 재현율(recall) 등을 사용.(여기서는 정확도를 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d70eb",
   "metadata": {},
   "source": [
    "## 2. 강아지 고양이 분류기 : 전이 학습(Transfer Learning)\n",
    "#### VGG16 모델을 가져와서 적용할 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef5d0c7",
   "metadata": {},
   "source": [
    "```Python\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "# 모델에서 이미지가 어떻게 변하는지 알아보자\n",
    "\n",
    "\n",
    "base_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n",
    "                                         include_top=False,\n",
    "                                         weights='imagenet')\n",
    "# pre-trained 모델인 VGG16 가져오기\n",
    "\n",
    "\n",
    "image_batch.shape\n",
    "# 적용하기 전 image_batch의 원래 사이즈를 다시 확인\n",
    "\n",
    "\n",
    "feature_batch = base_model(image_batch)\n",
    "feature_batch.shape\n",
    "# 모델을 적용한 결과물의 shape은 height, width는 각각 5로 매우 작아졌고, 512로 channel이 늘어났음\n",
    "\n",
    "\n",
    "base_model.summary()\n",
    "# 모델 구조 확인\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06891de0",
   "metadata": {},
   "source": [
    "#### 본격적인 모델 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55b7cf",
   "metadata": {},
   "source": [
    "```Python\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "dense_layer = tf.keras.layers.Dense(512, activation='relu')\n",
    "prediction_layer = tf.keras.layers.Dense(2, activation='softmax')\n",
    "prediction_batch = prediction_layer(dense_layer(feature_batch_average))  \n",
    "# 모델에 들어갈 Layer\n",
    "\n",
    "\n",
    "base_model.trainable = False\n",
    "# VGG16에 해당하는 base_model은 학습시키지 않을 예정이므로 학습 여부를 결정하는 trainable 변수를 False로 지정.\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "  dense_layer,\n",
    "  prediction_layer\n",
    "])\n",
    "# 모델 설계\n",
    "\n",
    "\n",
    "model.summary()\n",
    "# 모델 확인\n",
    "\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "# model compile\n",
    "\n",
    "\n",
    "validation_steps=20\n",
    "loss0, accuracy0 = model.evaluate(validation_batches, steps = validation_steps)\n",
    "\n",
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))\n",
    "# validation 데이터로 초기 model 학습을 한 뒤 확인.\n",
    "# 정확도가 50% 정도 나옴\n",
    "\n",
    "\n",
    "EPOCHS = 5   # 이번에는 이전보다 훨씬 빠르게 수렴되므로 5Epoch이면 충분합니다.\n",
    "\n",
    "history = model.fit(train_batches,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=validation_batches)\n",
    "# 모델 학습\n",
    "\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "# 시각화\n",
    "# 이미 훈련된 모델을 사용하자 직접 설계한 모델보다 좋은 결과.(정확도와 validation loss 모두 안정적)\n",
    "\n",
    "\n",
    "for image_batch, label_batch in test_batches.take(1):\n",
    "    images = image_batch\n",
    "    labels = label_batch\n",
    "    predictions = model.predict(image_batch)\n",
    "    pass\n",
    "\n",
    "predictions\n",
    "# test sample 32개로 prediction 생성\n",
    "# 마찬가지로 0~1 사이 확률값으로 나옴\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "predictions\n",
    "# 실제 추론한 라벨(0:고양이, 1:강아지)로 변환\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "for idx, (image, label, prediction) in enumerate(zip(images, labels, predictions)):\n",
    "    plt.subplot(4, 8, idx+1)\n",
    "    image = (image + 1) / 2\n",
    "    plt.imshow(image)\n",
    "    correct = label == prediction\n",
    "    title = f'real: {label} / pred :{prediction}\\n {correct}!'\n",
    "    if not correct:\n",
    "        plt.title(title, fontdict={'color': 'red'})\n",
    "    else:\n",
    "        plt.title(title, fontdict={'color': 'blue'})\n",
    "    plt.axis('off')\n",
    "# 예측 결과물 시각화\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "for idx, (image, label, prediction) in enumerate(zip(images, labels, predictions)):\n",
    "    plt.subplot(4, 8, idx+1)\n",
    "    image = (image + 1) / 2\n",
    "    plt.imshow(image)\n",
    "    correct = label == prediction\n",
    "    title = f'real: {label} / pred :{prediction}\\n {correct}!'\n",
    "    if not correct:\n",
    "        plt.title(title, fontdict={'color': 'red'})\n",
    "    else:\n",
    "        plt.title(title, fontdict={'color': 'blue'})\n",
    "    plt.axis('off')\n",
    "# 예측 정확도 확인\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd39d98",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. 모델에 checkpoint 적용 / 원하는 이미지를 넣어서 예측 결과 도출\n",
    "(미리 checkpoint 폴더와 원하는 이미지가 들어간 images 폴더를 만들어 두었음)<br><br>\n",
    "\n",
    "\n",
    "\n",
    "#### checkpoint 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd384ae",
   "metadata": {},
   "source": [
    "```Python\n",
    "import os\n",
    "\n",
    "checkpoint_dir = os.getenv(\"HOME\") + \"/Aiffel_Project/Dataset/cat_vs_dog/checkpoint\"\n",
    "checkpoint_file_path = os.path.join(checkpoint_dir, 'checkpoint')\n",
    "\n",
    "if not os.path.exists('checkpoint_dir'):\n",
    "    os.mkdir('checkpoint_dir')\n",
    "    \n",
    "model.save_weights(checkpoint_file_path)     # checkpoint 파일 생성\n",
    "\n",
    "if os.path.exists(checkpoint_file_path):\n",
    "  print('checkpoint 파일 생성 OK')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb19f0e4",
   "metadata": {},
   "source": [
    "#### 원하는 이미지를 모델에 적용해서 판별을 하는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537616c0",
   "metadata": {},
   "source": [
    "```Python\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "# load_img, img_to_array 함수를 가져와야 함\n",
    "\n",
    "\n",
    "IMG_SIZE = 160\n",
    "img_dir_path = os.getenv(\"HOME\") + \"/Aiffel_Project/Dataset/cat_vs_dog/checkpoint\"\n",
    "dog_image_path = os.path.join(img_dir_path, 'my_dog.jpg')\n",
    "\n",
    "dog_image = load_img(dog_image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "dog_image\n",
    "# 모델이 (160, 160) size만 적용 가능하므로 파라미터 입력하기\n",
    "# 강아지 이미지가 잘 적용이 됐는지 확인\n",
    "\n",
    "\n",
    "dog_image = img_to_array(dog_image).reshape(1, IMG_SIZE, IMG_SIZE, 3)\n",
    "dog_image.shape\n",
    "# 이미지를 array(배열) 자료형으로 변경\n",
    "\n",
    "\n",
    "prediction = model.predict(dog_image)\n",
    "prediction\n",
    "# 예측\n",
    "\n",
    "\n",
    "def show_and_predict_image(dirpath, filename, img_size=160):\n",
    "    filepath = os.path.join(dirpath, filename)\n",
    "    image = load_img(filepath, target_size=(img_size, img_size))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    image = img_to_array(image).reshape(1, img_size, img_size, 3)\n",
    "    prediction = model.predict(image)[0]\n",
    "    cat_percentage = round(prediction[0] * 100)\n",
    "    dog_percentage = round(prediction[1] * 100)\n",
    "    print(f\"This image seems {dog_percentage}% dog, and {cat_percentage}% cat.\")\n",
    "# 모델에 넣어서 예측 결과를 알려주는 함수를 생성    \n",
    "\n",
    "\n",
    "filename = 'my_dog.jpg'\n",
    "\n",
    "show_and_predict_image(img_dir_path, filename)\n",
    "# my_dog.jpg를 넣어서 함수가 잘 내놓는지 확인\n",
    "\n",
    "\n",
    "filename = 'my_cat.jpg'\n",
    "\n",
    "show_and_predict_image(img_dir_path, filename)\n",
    "# my_cat.jpg\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
