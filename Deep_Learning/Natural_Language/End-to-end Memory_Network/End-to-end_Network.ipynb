{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4330422c",
   "metadata": {},
   "source": [
    "# 메모리 네트워크 이해.\n",
    "End-to-End Memory Network를 구현해 보고, 이를 이용해서 bAbI 태스크를 직접 수행할 것.<br>\n",
    ">목표\n",
    "> * 두 개 이상의 입력을 받는 모델을 설계해본다.\n",
    "> * 메모리 구조를 사용하는 메모리 네트워크에 대해서 이해한다.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39c021f",
   "metadata": {},
   "source": [
    "## 1. 데이터셋 로드\n",
    "라이브러리를 호출한 뒤 bAbl 데이터셋을 로드할 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582e7c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import tarfile\n",
    "from nltk import FreqDist\n",
    "from functools import reduce\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05687c58",
   "metadata": {},
   "source": [
    "tf.keras의 get_file()을 통해 다운로드."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc9147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = os.getenv('HOME')+'/Aiffel_Project/Dataset/Babi_memory_net'\n",
    "file_to_save = home_dir + '/babi-tasks-v1-2.tar.gz'\n",
    "path = get_file(file_to_save, origin='https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz')\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f56b992",
   "metadata": {},
   "source": [
    "압축 파일이기 때문에 압축을 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7088656",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open(path) as tar:\n",
    "    tar.extractall(home_dir)  # ~/aiffel/babi_memory_net 아래에 압축해제\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b8203a",
   "metadata": {},
   "source": [
    "훈련 데이터의 경로와 테스트 데이터의 경로를 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b620bb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = home_dir + '/tasks_1-20_v1-2/en-10k'\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_train.txt\")\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a626cd9",
   "metadata": {},
   "source": [
    "훈련 데이터에서 20개의 문장을 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "lines = open(TRAIN_FILE , \"rb\")\n",
    "for line in lines:\n",
    "    line = line.decode(\"utf-8\").strip()\n",
    "    # lno, text = line.split(\" \", 1) # ID와 TEXT 분리\n",
    "    i = i + 1\n",
    "    print(line)\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a99a94",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리\n",
    "첫 번째 전처리는 데이터를 읽는 과정에서 스토리, 질문, 답변을 각각 분리해서 저장.<br>\n",
    "supporting fact(실제 정답이 몇번째 문장에 있었는지를 알려주는 인덱스 힌트 정보)는 저장하지 않을 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dir):\n",
    "    stories, questions, answers = [], [], [] # 각각 스토리, 질문, 답변을 저장할 예정\n",
    "    story_temp = [] # 현재 시점의 스토리 임시 저장\n",
    "    lines = open(dir, \"rb\")\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.decode(\"utf-8\") # b' 제거\n",
    "        line = line.strip() # '\\n' 제거\n",
    "        idx, text = line.split(\" \", 1) # 맨 앞에 있는 id number 분리\n",
    "        # 여기까지는 모든 줄에 적용되는 전처리\n",
    "\n",
    "        if int(idx) == 1:\n",
    "            story_temp = []\n",
    "        \n",
    "        if \"\\t\" in text: # 현재 읽는 줄이 질문 (tab) 답변 (tab)인 경우\n",
    "            question, answer, _ = text.split(\"\\t\") # 질문과 답변을 각각 저장\n",
    "            stories.append([x for x in story_temp if x]) # 지금까지의 누적 스토리를 스토리에 저장\n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "\n",
    "        else: # 현재 읽는 줄이 스토리인 경우\n",
    "            story_temp.append(text) # 임시 저장\n",
    "\n",
    "    lines.close()\n",
    "    return stories, questions, answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c88539",
   "metadata": {},
   "source": [
    "read_data()를 통해 스토리, 질문, 답변의 쌍을 리턴하여 훈련 데이터는 train_data()에, 테스트 데이터는 test_data()에 저장함.<br>\n",
    "두 데이터를 가지고 추가적인 전처리를 진행할 예정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48db60f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data(TRAIN_FILE)\n",
    "test_data = read_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04415a1f",
   "metadata": {},
   "source": [
    "확인하기 쉽도록 스토리, 질문, 답변을 각각 저장하고 직접 출력해 볼 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f4713",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
    "test_stories, test_questions, test_answers = read_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e03412a",
   "metadata": {},
   "source": [
    "각각의 샘플 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688166b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train 스토리 개수:\", len(train_stories))\n",
    "print(\"train 질문 개수:\", len(train_questions))\n",
    "print(\"train 답변 개수:\", len(train_answers))\n",
    "print(\"test 스토리 개수:\", len(test_stories))\n",
    "print(\"test 질문 개수:\", len(test_questions))\n",
    "print(\"test 답변 개수:\", len(test_answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd04f32",
   "metadata": {},
   "source": [
    "훈련 데이터는 10,000개 테스트 데이터는 1,000개임을 알 수 있음.<br><br>\n",
    "\n",
    "임의로 3,879번째 스토리를 출력.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba047b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stories[3878]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5ee89",
   "metadata": {},
   "source": [
    "상위 5개의 질문을 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96567020",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_questions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b875c5c",
   "metadata": {},
   "source": [
    "상위 5개의 답변을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a993203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_answers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efca69f4",
   "metadata": {},
   "source": [
    "### 토큰화를 위한 함수를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e7e32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    return [ x.strip() for x in re.sub(r\"\\s+|\\b\", '\\f', sent).split('\\f') if x.strip() ] # python 3.7의 경우 \n",
    "    # return [ x.strip() for x in re.split('(\\W+)?', sent) if x.strip()] # python 3.6의 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec7bfed",
   "metadata": {},
   "source": [
    "### 단어장을 생성하고, 단어에서 정수로, 정수에서 단어로 맵핑하는 딕셔너리(dictionary)를 생성.\n",
    "스토리와 질문의 가장 긴 길이를 구해서 padding 적용 과정에 이용할 것.<br><br>\n",
    "\n",
    "\n",
    "단, 전처리를 하면서 같은 스토리 내의 여러 문장들 하나의 문장으로 통합할 것.<br>\n",
    "가령, 앞서 3,879번째 스토리는 8개의 문장으로 구성되어 있으나 전처리 과정에서 8개의 문장을 모두 이어 붙여서 1개의 문장으로 통합."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48100847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_data, test_data):\n",
    "    counter = FreqDist()\n",
    "    \n",
    "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    # 각 샘플의 길이를 저장하는 리스트\n",
    "    story_len = []\n",
    "    question_len = []\n",
    "    \n",
    "    for stories, questions, answers in [train_data, test_data]:\n",
    "        for story in stories:\n",
    "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
    "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
    "            for word in stories: # 단어 집합에 단어 추가\n",
    "                counter[word] += 1\n",
    "        for question in questions:\n",
    "            question = tokenize(question)\n",
    "            question_len.append(len(question))\n",
    "            for word in question:\n",
    "                counter[word] += 1\n",
    "        for answer in answers:\n",
    "            answer = tokenize(answer)\n",
    "            for word in answer:\n",
    "                counter[word] += 1\n",
    "\n",
    "    # 단어장 생성\n",
    "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
    "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
    "\n",
    "    # 가장 긴 샘플의 길이\n",
    "    story_max_len = np.max(story_len)\n",
    "    question_max_len = np.max(question_len)\n",
    "\n",
    "    return word2idx, idx2word, story_max_len, question_max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f91a7b",
   "metadata": {},
   "source": [
    "전처리 함수를 사용하여 단어장과 가장 긴 샘플의 길이를 리턴 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097a0926",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa2d7f4",
   "metadata": {},
   "source": [
    "단어장을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eb9a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a049ac",
   "metadata": {},
   "source": [
    "실제 변수로 사용할 단어장의 크기는 패딩을 고려하여 +1 을 해주어야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189e3717",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2idx) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eac202",
   "metadata": {},
   "source": [
    "전처리 함수를 통해 구한 스토리와 질문의 최대 길이 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50275eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('스토리의 최대 길이 :',story_max_len)\n",
    "print('질문의 최대 길이 :',question_max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9616a6fd",
   "metadata": {},
   "source": [
    "* 스토리의 최대 길이는 68가 나옴.  이는 스토리 내에 있는 여러 개 문장들을 하나의 문장으로 간주하였을 때, 최대 단어의 개수.<br>\n",
    "* 질문의 최대 길이는 4. bAbI 데이터셋에는 대체로 'Where is Mary?'와 같은 매우 짧은 길이의 질문들만 존재한다는 의미."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7791151e",
   "metadata": {},
   "source": [
    "### 남은 전처리를 진행하는 함수 생성\n",
    "\n",
    "* 텍스트 데이터를 단어와 맵핑되는 정수로 인코딩. 이 과정은 앞서 만들어놓은 word2idx를 활용.\n",
    "* 스토리와 질문 데이터에 대해서 각각의 최대 길이로 패딩(padding). 이 과정은 앞서 계산해놓은 story_max_len과 question_max_len을 사용.\n",
    "* 레이블에 해당되는 정답 데이터를 원-핫 인코딩."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f683fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
    "    Xs, Xq, Y = [], [], []\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    stories, questions, answers = data\n",
    "    for story, question, answer in zip(stories, questions, answers):\n",
    "        xs = [word2idx[w] for w in tokenize(flatten(story))]\n",
    "        xq = [word2idx[w] for w in tokenize(question)]\n",
    "        Xs.append(xs)\n",
    "        Xq.append(xq)\n",
    "        Y.append(word2idx[answer])\n",
    "\n",
    "    # 스토리와 질문은 각각의 최대 길이로 패딩\n",
    "    # 정답은 원-핫 인코딩\n",
    "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
    "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
    "           to_categorical(Y, num_classes=len(word2idx) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634111dd",
   "metadata": {},
   "source": [
    "훈련 데이터와 테스트 데이터에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcdfe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
    "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b5d8b6",
   "metadata": {},
   "source": [
    "반환된 결과의 크기(shape)를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8e51f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape, Xstest.shape, Xqtest.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c4fd42",
   "metadata": {},
   "source": [
    "## 3. 메모리 네트워크 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c5afdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Permute, dot, add, concatenate\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Activation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0920be95",
   "metadata": {},
   "source": [
    "하이퍼파라미터를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18b67a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에포크 횟수\n",
    "train_epochs = 120\n",
    "# 배치 크기\n",
    "batch_size = 32\n",
    "# 임베딩 크기\n",
    "embed_size = 50\n",
    "# LSTM의 크기\n",
    "lstm_size = 64\n",
    "# 과적합 방지 기법인 드롭아웃 적용 비율\n",
    "dropout_rate = 0.30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22472fac",
   "metadata": {},
   "source": [
    "입력을 담아두는 변수들을 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2707cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((story_max_len,))\n",
    "question = Input((question_max_len,))\n",
    " \n",
    "print('Stories :', input_sequence)\n",
    "print('Question:', question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1692d256",
   "metadata": {},
   "source": [
    "#### 먼저 텍스트 입력을 임베딩으로 변환하는 인코더를 구현\n",
    "![embedding encoder](embedding_encoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b1f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스토리를 위한 첫 번째 임베딩. 그림에서의 Embedding A\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=embed_size))\n",
    "input_encoder_m.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, embed_size) / 샘플의 수, 문장의 최대 길이, 임베딩 벡터의 차원\n",
    " \n",
    "# 스토리를 위한 두 번째 임베딩. 그림에서의 Embedding C\n",
    "# 임베딩 벡터의 차원을 question_max_len(질문의 최대 길이)로 한다.\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=question_max_len))\n",
    "input_encoder_c.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이(임베딩 벡터의 차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe5af66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문을 위한 임베딩. 그림에서의 Embedding B\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=embed_size,\n",
    "                               input_length=question_max_len))\n",
    "question_encoder.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, question_max_len, embed_size) / 샘플의 수, 질문의 최대 길이, 임베딩 벡터의 차원"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56801e7e",
   "metadata": {},
   "source": [
    "#### 구현된 인코더를 이용해 텍스트를 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed7a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실질적인 임베딩 과정\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "print('Input encoded m', input_encoded_m, '\\n')\n",
    "print('Input encoded c', input_encoded_c, '\\n')\n",
    "print('Question encoded', question_encoded, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f4dabc",
   "metadata": {},
   "source": [
    "###  스토리 문장과 질문 문장의 매칭 유사도 계산 구현\n",
    "![soft attention 방식의 유사도 구하기](soft_attention.png)\n",
    "\n",
    "\n",
    "<center>(soft attention 방식의 유사도 구하기)</center>\n",
    "\n",
    "\n",
    "$$ p = Softmax(dot(m,u)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9060cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스토리 단어들과 질문 단어들 간의 유사도를 구하는 과정\n",
    "# 유사도는 내적을 사용한다.\n",
    "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
    "match = Activation('softmax')(match)\n",
    "print('Match shape', match)\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b662a9",
   "metadata": {},
   "source": [
    "예측에 사용되는 출력 행렬은 매칭 유사도 match와 스토리 표현 input_encoded_c을 더해서 도출."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88404a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매칭 유사도 행렬과 질문에 대한 임베딩을 더한다.\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, question_max_len)\n",
    "response = Permute((2, 1))(response)  # (samples, question_max_len, story_maxlen)\n",
    "print('Response shape', response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf53ef9",
   "metadata": {},
   "source": [
    "## 4. 모델 정의 및 훈련 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd566755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the response vector with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])\n",
    "print('Answer shape', answer)\n",
    " \n",
    "answer = LSTM(lstm_size)(answer)  # Generate tensors of shape 32\n",
    "answer = Dropout(dropout_rate)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d366ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 모델 컴파일\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    " \n",
    "# 테스트 데이터를 검증 데이터로 사용하면서 모델 훈련 시작\n",
    "history = model.fit([Xstrain, Xqtrain],\n",
    "         Ytrain, batch_size, train_epochs,\n",
    "         validation_data=([Xstest, Xqtest], Ytest))\n",
    " \n",
    "# 훈련 후에는 모델 저장\n",
    "model_path = os.getenv('HOME')+'/aiffel/babi_memory_net/model.h5'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcbaeb3",
   "metadata": {},
   "source": [
    "테스트 정확도를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fae007",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate([Xstest, Xqtest], Ytest)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efb0196",
   "metadata": {},
   "source": [
    "#### 훈련 과정에서 기록해두었던 훈련 데이터, 검증 데이터의 정확도와 loss를 그래프로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e29093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy and loss plot\n",
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# labels\n",
    "ytest = np.argmax(Ytest, axis=1)\n",
    "\n",
    "# get predictions\n",
    "Ytest_ = model.predict([Xstest, Xqtest])\n",
    "ytest_ = np.argmax(Ytest_, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba80e71",
   "metadata": {},
   "source": [
    "테스트 데이터에 대해 실제로 문제를 잘 맞추는지 임의로 예측 결과 30개를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28efb97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DISPLAY = 30\n",
    "\n",
    "print(\"{:20}|{:7}|{}\".format(\"질문\", \"실제값\", \"예측값\"))\n",
    "print(39 * \"-\")\n",
    "\n",
    "for i in range(NUM_DISPLAY):\n",
    "    question = \" \".join([idx2word[x] for x in Xqtest[i].tolist()])\n",
    "    label = idx2word[ytest[i]]\n",
    "    prediction = idx2word[ytest_[i]]\n",
    "    print(\"{:20}: {:8} {}\".format(question, label, prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
